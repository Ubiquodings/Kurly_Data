{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 판다스\n",
    "\n",
    "#판다스의 핵심 객체 DataFrame\n",
    "#다른 중요 객체 Index, Series\n",
    "#Index는 RDMS의 PK처럼, 개별 데이터를 고유하게 식별하는 Key값\n",
    "#Series, DataFrame은 모두 Index를 키 깂으로 갖고 있다\n",
    "#Series와 DataFrame의 가장 큰 차이는,\n",
    "#  Series는 칼럼이 하나뿐인 데이터 구조체,\n",
    "#  DataFrame은 칼럼이 여러 개인 데이터 구조체\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 판다스 시작 - 파일을 DataFrame으로 로딩, 기본 API\n",
    "판다스는 다양한 포맷으로 된 파일을 DataFrame으로 로딩할 수 있는 편리한 API를 제공합니다.\n",
    "    대표적으로 read_csv(), read_table(), read_fwf()가 있습니다.\n",
    "    read_csv()는 칼럼을 , 로 구분한 파일 포맷 CSV 변환을 위한 API입니다.\n",
    "    read_table()은 칼럼은 \\t로 구분하는 파일 포맷을 변환합니다.\n",
    "    \n",
    "    read_csv()는 CSV뿐만 아니라, 어떤 필드 구분 문자 기반의 파일 포맷도 DataFrame으로 변환이 가능합니다.\n",
    "    read_csv()의 인자인 sep에 해당 구분 문자를 입력하면 됩니다.\n",
    "    가령 탭으로 필드가 구분되어 있다면 read_csv('파일명', sep='\\t')과 같이 기술합니다.\n",
    "    read_csv()에서 sep인자를 생략하면 자동으로 콤마로 할당됩니다.\n",
    "    \n",
    "    read_csv()와 read_table()은 기능상 큰 차이가 없으므로 read_csv()만 사용합니다.\n",
    "    read_fwf()는 Fixed Width, 즉 고정 길이 기반의 칼럼 포맷을 DataFrame으로 로딩하기 위한 API입니다.\n",
    "    \n",
    "read_csv()에서 가장 중요한 인자는 filepath입니다.\n",
    "    나머지 인자는 지정하지 않으면 dafult 값으로 할당됩니다.\n",
    "    ex) pd.read_csv('titanic_train.csv')\n",
    "    \n",
    "    pd.read_csv()는 호출 시, 파일을 로딩해 DataFrame 객체로 반환합니다.\n",
    "    \n",
    "    데이터 파일의 첫 번째 줄에 있던 칼럼 문자열이 DataFrame의 칼럼으로 할당됩니다.\n",
    "    모든 DataFrame 내의 데이터는 생성되는 순간, 고유의 Index 값을 가지게 됩니다.\n",
    "    \n",
    "    DataFrame.head()는 DataFrame의 맨 앞에 있는 N개의 로우를 반환합니다. default 5\n",
    "    ex) titanic_df.head()\n",
    "    \n",
    "    DataFrame의 행과 열 크기를 알아보는 가장 좋은 방법은 생성된 DataFrame 객체의 shape 변수를 이용하는 것.\n",
    "    shape은 DataFrame의 행과 열을 튜플 형태로 반환한다.\n",
    "    ex) titanic_df.shape #(891,12)\n",
    "    \n",
    "    DataFrame은 데이터뿐만 아니라 \n",
    "    칼럼의 타입, Null 데이터 개수, 데이터 분포도 등의 메타 데이터 등의 조회가 가능하다.\n",
    "    대표적인 메서드로 info()와 describe()가 있다.\n",
    "    ex) titanic_df.info()\n",
    "        \n",
    "        >> RangeIndex는 DataFrame index의 범위를 나타낸다. 전체 row 수를 알 수 있다.\n",
    "           칼럼별 데이터 타입, 몇 개의 데이터가 non-null인지, 전체 칼럼들 타입 요약 등을 알 수 있다.\n",
    "        \n",
    "        info()를 통해 총 데이터 거수와 데이터 타입, Null 건수를 알 수 있다.\n",
    "        \n",
    "    describe()는 칼럼별 숫자형 데이터 값을 n-percentile 분포도, 평균값, 최대/최솟값을 나타낸다.\n",
    "    describe()는 오직 숫자형-int,float 칼럼의 분포도만 조사하며,\n",
    "    자동으로 object 타입의 칼럼은 출력에서 제외된다.\n",
    "    \n",
    "    데이터의 분포도를 아는 것은 머신러닝 알고리즘의 성능을 향상시키는 중요한 요소이다.\n",
    "    가령, 회귀에서 결정 값이 정규 분포를 이루지 않고 특정 값으로 왜곡돼 있는 경우,\n",
    "    또는 데이터값이 이상치가 많을 경우 예측 성능이 저하됩니다.\n",
    "    describe()만으로 정확한 분포도를 알기는 무리지만, 개략적인 수준의 분포도를 확인할 수 있어 유용하다.\n",
    "    ex) titanic_df.describe()\n",
    "         >> count는 Not Null인 데이터 건수, mean은 전체 데이터의 평균값, std는 표준편차, min은 최소, max는 최대값.\n",
    "            그리고 25%는 25 percentile 값, 50%,75%도 마찬가지.\n",
    "            \n",
    "    또한 describe()는 해당 숫자 칼럼이 숫자형 카테고리 칼럼인지 판단할 수 있게 한다.\n",
    "    카테고리 칼럼은 특정 범주에 속하는 값을 코드화한 칼럼이다.\n",
    "    가령 성별 칼럼의 경우 남, 여가 있고 남을 1, 여를 2와 같이 표현한 것.\n",
    "    이러한 카테고리 칼럼을 숫자로 표시할 수도 있는데, describe()를 통해 확인할 수 있다.\n",
    "    min,25%,50%,75%,max를 보고 파악할 수 있다.\n",
    "    \n",
    "DataFrame의 [] 연산자 내부에 칼럼명을 입력하면 Series 형태로 특정 칼럼 데이터 세트가 반환된다.\n",
    "    반환된 Series 객체에 value_counts()를 호출하면 해당 칼럼값의 유형과 건수를 확인할 수 있다.\n",
    "    value_counts()는 지정된 칼럼의 데이터값 건수를 반환한다. \n",
    "    (주로 카테고리 칼럼 분포 확인에 사용되겠군)\n",
    "    value_counts()는 데이터의 분포도를 확인하는 데 매우 유용한 함수이며, 매우 자주 사용됩니다.\n",
    "    ex) titanic_df['Pclass'].value_counts()\n",
    "    \n",
    "    value_counts()는 많은 건수 순서로 정렬되어 값을 반환합니다.\n",
    "\n",
    "Series는 Index와 단 하나의 칼럼으로 구성된 데이터 세트.\n",
    "    모든 Series와 DataFrame은 인덱스를 반드시 가진다.\n",
    "    value_counts()는 Series 객체에만 정의되어 있다.\n",
    "    value_counts()가 반환하는 데이터 타입 역시 Series 객체.\n",
    "    \n",
    "    인덱스는 단수히 순차 값과 같은, 의미없는 식별자만 할당하는 것이 아니라\n",
    "    고유성이 보장된다면 의미 있는 데이터값 할당도 가능하다.\n",
    "    value_counts()는 칼럼 값별 데이터 건수를 반환하므로, 고유 칼럼 값을 식별자로 사용할 수 있다. ?\n",
    "    \n",
    "    인덱스는 DataFrame, Series가 만들어진 후에도 변경할 수 있다.\n",
    "    인덱스는 또한 숫자형뿐만 아니라 문자열도 가능하다.\n",
    "    단, 모든 인덱스는 고유성이 보장되어야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 DataFrame과 리스트, 딕셔너리, 넘파이 ndarray 상호 변환\n",
    "csv 파일을 read_csv()를 이용해 DataFrame으로 생성합니다.\n",
    "기본적으로 DataFrame은 파이썬의 리스트,딕셔너리,넘파이 ndarray 등 다양한 데이터로부터 생성될 수 있습니다.\n",
    "또한 DataFrame은 반대로 파이썬의 리스트, 딕셔너리, 넘파이 ndarray 등으로 변환될 수 있습니다.\n",
    "특히 사이킷런의 많은 API는 DataFrame을 인자로 입력받을 수 있지만,\n",
    "    기본적으로 넘파이 ndarray를 입력 인자로 사용하는 경우가 대부분입니다.\n",
    "    따라서 DataFrame과 넘파이 ndarray 상호 간의 변환은 매우 빈번하게 발생합니다.\n",
    "\n",
    "# -넘파이 ndarray, 리스트, 딕셔너리를 DataFrame으로 변환하기\n",
    "DataFrame은 리스트와 넘파이 ndarray와 다르게 칼럼명을 갖고 있다.\n",
    "이 칼럼명으로 인해 리스트와 넘파이ndarray보다 보다 편하게 데이터 핸들링이 가능하다.\n",
    "일반적으로 DataFrame으로 변환 시 이 칼럼명을 지정해 준다.\n",
    "    지정하지 않으면 자동으로 칼럼명 할당한다.\n",
    "    \n",
    "판다스 DataFrame 객체의 생성 인자 data는 리스트나 딕셔너리, ndarray를 입력받고,\n",
    "    생성 인자 columns는 칼럼명 리스트를 입력 받아서 쉽게 DataFrame을 생성할 수 있다.\n",
    "    \n",
    "    DataFrame은 기본적으로 행과 열을 가지는 2차원 데이터이다.\n",
    "    따라서 2차원 이하의 데이터들만 DataFrame으로 변환할 수 있다.\n",
    "    \n",
    "    먼저 1차원 형태의 리스트와 넘파이 ndarray부터 DataFrame으로 변환해보자.\n",
    "    ex) col_name = ['col1']\n",
    "        list1 = [1,2,3]\n",
    "        array1 = np.array(list1)\n",
    "        \n",
    "        pd.DataFrame(list1, columns=col_name) #col_name = ['col1']\n",
    "        pd.DataFrame(array1, columns=col_name)\n",
    "        \n",
    "    2차원 형태의 데이터를 기반으로 DataFrame을 생성해보자.\n",
    "    2행3열 형태의 리스트와 ndarray를 기반으로 DataFrame을 생성하므로 칼럼명은 3개가 필요합니다.\n",
    "    ex) col_name = ['col1','col2','col3']\n",
    "        list2 = [[1,2,3],[11,12,13]]\n",
    "        array2 = np.array(list2)\n",
    "        \n",
    "        pd.DataFrame(list2, columns=col_name)\n",
    "        pd.DataFrame(array2, columns=col_name)\n",
    "        \n",
    "    딕셔너리를 DataFrame으로 변환해보자.\n",
    "    일반적으로 딕셔너리를 DataFrame으로 변환 시에는 딕셔너리의 키는 칼럼명으로,\n",
    "    딕셔너리의 값은 키에 해당하는 칼럼 데이터로 변환된다.\n",
    "    따라서 키는 문자열, 값은 리스트,ndarray 형태로 딕셔너리를 구성한다.\n",
    "    ex) dict = {'col1':[1,11], 'col2':[2,12], 'col3':[3,13]}\n",
    "        pd.DataFrame(dict)\n",
    "\n",
    "# -DataFrame을 넘파이 ndarray, 리스트, 딕셔너리로 변환하기\n",
    "많은 머신러닝 패키지가 기본 데이터 형으로 넘파이 ndarray를 사용한다.\n",
    "따라서 데이터 핸들링은 DataFrame을 이용하더라도, \n",
    "    머신러닝 패키지의 입력 인자 등에 적용하기 위해 다시 넘파이 ndarray로 변환해야 하는 경우가 빈번하다.\n",
    "    DataFrame을 넘파이 ndarray로 변환하는 것은 DataFrame 객체의 values를 이용해 쉽게 할 수 있다.\n",
    "    \n",
    "    DataFrame 객체 df_dict를 ndarray로 변환해보자.\n",
    "    ex) array2 = df_dict.values\n",
    "    \n",
    "    DataFrame을 리스트와 딕셔너리로 변환해보자.\n",
    "    리스트로의 변환은 values로 얻은 ndarray에 tolist()를 호출하면 된다.\n",
    "    딕셔너리로의 변환은 DataFrame 객체의 to_dict()를 호출한다.\n",
    "        인자로 'list'를 입력하면 딕셔너리의 값이 리스트형으로 반환된다.\n",
    "        ex) list = df_dict.values.tolist()\n",
    "            dict = df_dict.to_dict('list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 DataFrame의 칼럼 데이터 세트 생성과 수정\n",
    "DataFrame의 칼럼 데이터 세트 생성과 수정은 [] 연산자를 이용하여 쉽게 할 수 있습니다.\n",
    "ex) Titanic DataFrame의 새로운 칼럼 Age_0을 추가하고 일괄적으로 0값을 할당해보자\n",
    "    titanic_df['Age_0'] = 0 # Series에 값을 할당하고 DataFrame에 추가\n",
    "    \n",
    "    넘파이의 ndarray에 상숫값을 할당할 때도, 모든 ndarray 값에 일괄 적용된다.\n",
    "    \n",
    "    기존 칼럼 Series의 데이터를 이용해 새로운 칼럼 Series를 만들어보자.\n",
    "    titanic_df['Age_by_10'] = titanic_df['Age'] * 10\n",
    "    titanic_df['Family_No'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 DataFrame 데이터 삭제\n",
    "DataFrame에서 데이터의 삭제는 drop()을 이용합니다.\n",
    "drop()은 사용에 주의가 필요합니다.\n",
    "가장 중요한 파라미터는 labels,axis,inplace입니다.\n",
    "    먼저 axis 값에 따라 특정 칼럼 또는 특정 행을 드롭합니다.\n",
    "    판다스의 DataFrame은 2차원 데이터만 다루므로 axis 0,axis 1로만 구성되어 있습니다.\n",
    "    \n",
    "drop()에 axis=1을 입력하면, 칼럼 축 방향으로 드롭을 수행하므로,\n",
    "    칼럼을 드롭하겠다는 의미입니다.\n",
    "    labels에 원하는 칼럼 명을 입력하고 axis=1을 입력하면, 지정된 칼럼을 드롭합니다.\n",
    "    \n",
    "    drop()에 axis=0을 입력하면 로우 축 방향으로 드롭을 수행하므로,\n",
    "    특정 로우를 드롭하겠다는 것입니다.\n",
    "    DataFrame의 특정 로우를 가리키는 것은 인덱스입니다.\n",
    "    따라서 axis를 0으로 지정하면 DataFrame은 자동으로 labels에 오는 값을 인덱스로 간주합니다.\n",
    "    \n",
    "drop()이 사용되는 대부분의 경우는 칼럼을 드롭하는 경우입니다.\n",
    "    기존 칼럼 값을 가공해 새로운 칼럼을 만들고 삭제하는 경우가 많다보니,\n",
    "    axis를 1로 설정하고 드롭하는 경우가 많을 수밖에 없습니다.\n",
    "    axis=0으로 설정하고 로우 레벨로 삭제를 하는 경우는 \n",
    "    이상치 데이터를 삭제하는 경우에 주로 사용됩니다.\n",
    "    ex) Titinic DataFrame에 추가된 Age_0 칼럼을 삭제합니다\n",
    "        titanic_df.drop('Age_0',axis=1)\n",
    "        \n",
    "    여러 개의 칼럼을 삭제하고 싶으면, 리스트 형태로 삭제하고자 하는 칼럼 명을 입력해\n",
    "    labels 파라미터로 입력하면 됩니다.\n",
    "    ex) titanic_df의 Age_0,Age_by_10,Family_No 칼럼을 삭제합니다.\n",
    "        titanic_df.drop(['Age_0','Age_by_10','Family_No'], axis=1, inplace=True)\n",
    "        \n",
    "        유의할 점은, inplace=True로 설정하면 반환값이 None이다.\n",
    "        \n",
    "        axis=0으로 설정해 index 0,1,2 로우를 삭제해보자.\n",
    "        pd.set_option('display.width', 1000)\n",
    "        pd.set_option('display.max_colwidth', 15)\n",
    "        titanic_df.drop([0,1,2], axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Index 객체\n",
    "Pandas의 Index 객체는, \n",
    "    DataFrame, Series의 레코드를 고유하게 식별하는 객체이다.\n",
    "    DataFrame, Series에서 Index 객체만 추출하려면,\n",
    "    DataFrame.index, Series.index 속성을 이용하면 된다.\n",
    "    반환된 Index 객체의 실제 값은, Numpy 1차원 ndarray이다.\n",
    "    Index 객체의 values 속성으로 ndarray 값을 확인할 수 있다.\n",
    "ex) titanic_df = pd.read_csv('titanic_train.csv')\n",
    "    indexes = titanic_df.index # Index 객체 추출\n",
    "    indexes.values # Index 객체를, 실제 값 array로 변환 <- 변환?반환?\n",
    "    \n",
    "Index 객체는 식별성 데이터를 1차원 array로 갖는다.\n",
    "또한, ndarray와 유사하게 단일 값 반환 및 슬라이싱도 가능하다.\n",
    "ex) indexes[:5].values\n",
    "    indexes.values[:5]\n",
    "    indexes[6]\n",
    "    \n",
    "그러나 한 번 만들어진 DataFrame, Series의 Index 객체는 변경할 수 없다.\n",
    "ex) indexes[0] = 5 # 오류\n",
    "\n",
    "Series 객체는 Index 객체를 포함하지만, Series 객체에 연산 함수를 적용할 때,\n",
    "    Index는 연산에서 제외된다.\n",
    "    Index는 오직 식별용으로만 사용한다.\n",
    "    \n",
    "DataFrame, Series에 reset_index()를 적용하면, 새롭게 인덱스를 연속 숫자형으로 할당한다.\n",
    "    기존 인덱스는 index라는 새로운 칼럼 명으로 추가된다.\n",
    "    ex) titanic_reset_df = titanic_df.reset_index(inplace=False)\n",
    "        titanic_reset_df.head(3)\n",
    "        \n",
    "    reset_index()는, 인덱스가 연속된 int 숫자형 데이터가 아닐 경우에\n",
    "    다시 이를 연속 int 숫자형 데이터로 만들 때 주로 사용합니다.\n",
    "    \n",
    "    Series에 reset_index()를 적용하면, DataFrame이 반환됩니다.\n",
    "    reset_index()의 매개 drop=True로 지정하면,\n",
    "    기존 인덱스는 새로운 칼럼으로 추가되지 않고 삭제된다.\n",
    "    새로운 칼럼이 추가되지 않았으므로 Series로 유지된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 데이터 셀렉션 및 필터링\n",
    "Numpy와 Pandas의 데이터 셀렉션 뿐만 아니라,\n",
    "    Pandas의 DataFrame과 Series끼리도 데이터 셀렉션 기능이 다르므로 주의해야 합니다.\n",
    "    Numpy의 경우, []연산자 내 단일 값 추출, 슬라이싱, 팬시 인덱싱, 불린 인덱싱을 통해 데이터를 추출합니다.\n",
    "    Pandas의 경우, ix[], iloc[], loc[] 연산자를 통해 동일한 작업을 수행합니다.\n",
    "\n",
    "# -DataFrame의 []연산자\n",
    "Numpy의 []연산자는 행위 위치, 열의 위치, 슬라이싱 범위 등을 지정해 데이터를 가져옵니다.\n",
    "Pandas에서는 DataFrame의 []연산자에 들어갈 수 있는 것은,\n",
    "    칼럼 명 문자열 또는 칼럼 명의 리스트, 인덱스로 변환 가능한 표현식입니다.\n",
    "    현재 수준에서는 DataFrame 뒤의 []연산자는 칼럼만 지정할 수 있는 '칼럼 지정 연산자'로 이해하는 것이 가장 좋습니다.\n",
    "    DataFrame['칼럼명'] 또는 DataFrame[['칼럼명1','칼럼명2',...]]\n",
    "    DataFrame[0], DataFrame[0,0], DataFrame[[0,0,0]] 같은 표현식은 오류.\n",
    "    \n",
    "ex) print('단일 칼럼 데이터 추출', titanic_df['Pclass'])\n",
    "    print('여러 칼럼 데이터 추출', titanic_df[['Survived','Pclass']])\n",
    "    \n",
    "Pandas-DataFrame의 []내에 숫자 값을 입력할 경우, 오류가 발생하지만,\n",
    "    Pandas의 인덱스 형태로 변환 가능한 표현식은 []내에 입력할 수 있습니다.\n",
    "    ex) titanic_df의 처음 2개 데이터를 추출한다.\n",
    "        titanic_df[0:2] # 사용하지 않는게 좋단다\n",
    "        \n",
    "    불린 인덱싱 표현도 가능.\n",
    "    원하는 데이터를 편리하게 추출해 주므로 자주 사용된다.\n",
    "    ex) titanic_df[ titanic_df['Pclass']==3 ].head(3)\n",
    "\n",
    "# -DataFrame ix[] 연산자\n",
    "deprecated 되었다.\n",
    "이를 대신하는,\n",
    "    칼럼 명칭 기반 인덱싱 연산자 loc[],\n",
    "    칼럼 위치 기반 인덱싱 연산자 iloc[]가 주로 사용된다.\n",
    "    # 가독성을 위해..    \n",
    "\n",
    "# -명칭 기반 인덱싱, 위치 기반 인덱싱\n",
    "결과적으로, DataFrame은 명칭 기반 인덱싱이라고 간주하면 편한가보다.\n",
    "\n",
    "# -DataFrame iloc[] 연산자\n",
    "ex) data_df.iloc[0,0]\n",
    "    >> 0행 0열 값 출력한다.\n",
    "    data_df.iloc[0:1, 0]\n",
    "    >> 0행부터 1행전까지의 행과 0열 값을 출력한다.\n",
    "\n",
    "# -DataFrame loc[] 연산자\n",
    "ex) data_df.loc['one','Name']\n",
    "    >>'one'행 'Name'칼럼 값을 출력한다.\n",
    "    data_df.loc['one':'two', 'name']\n",
    "    >> one, two 행의 name 열 값들을 출력한다\n",
    "    data_df_reset.loc[1:2, 'Name'] # 1:2는 DataFrame의 인덱스값에 따른 명칭 기반 인덱싱이란다 시발\n",
    "\n",
    "# -불린 인덱싱\n",
    "ex) titanic_df[ titanic_df['Age']>60 ] # DataFrame 반환\n",
    "    titanic_df[ titanic_df['Age']>60 ][['Name','Age']]\n",
    "    titanic_df.loc[ titanic_df['Age']>60, ['Name','Age'] ]\n",
    "    \n",
    "    나이가 60세 이상이고, 선실 등급이 1등급이며, 성별이 여성인 승객 추출.\n",
    "    복합 조건 연산자는 개별 조건을 ()로 묶어 사용한다.\n",
    "    titanic_df[ (titanic_df['Age']>=60) & (titanic_df['Sex']=='female') & (titanic_df['Pclass']==1) ]\n",
    "    \n",
    "    개별 조건을 변수에 할당하고, 변수를 결합하여 불린 인덱싱을 수행할 수도 있다.\n",
    "    cond1 = titanic_df['Age']>=60\n",
    "    cond2 = titanic_df['Pclass']==1\n",
    "    cond3 = titanic_df['Sex']=='female'\n",
    "    titanic_df[ cond1 & cond2 & cond3 ]\n",
    "    \n",
    "불린 인덱싱은 유연하고, loc[]에서 시용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 정렬, Aggregation 함수, GroupBy 적용\n",
    "\n",
    "# -DataFrame, Series의 정렬 - sort_values()\n",
    "sort_values(): DataFrame과 Series의 정렬을 수행.\n",
    "sort_values()는 RDBMS SQL의 order by 키워드와 유사하다.\n",
    "\n",
    "sort_values()의 주요 파라미터:\n",
    "    by - by로 특정 칼럼을 입력하면, 해당 칼럼으로 정렬을 수행한다.\n",
    "    ascending=True(default)로 설정하면 오름차순 정렬, ascending=False이면 내림차순 정렬.\n",
    "    inplace=False(default)로 설정하면 호출한 DataFrame 그대로 유지, inplace=True이면 정렬 결과 적용.\n",
    "\n",
    "ex) Name 칼럼으로 오름차순 정렬.\n",
    "    titanic_df.sort_values(by=['Name'], inplace=True)\n",
    "    \n",
    "여러 개의 칼럼으로 정렬하려면, by에 리스트 형식으로 칼럼 전달.\n",
    "ex) Pclass, Name으로 내림차순 정렬\n",
    "    titanic_df.sort_values(by=['Pclass','Name'], ascending=False, inplace=True)\n",
    "    # 데이터 전처리할 때마다 주석 달아서 알아보기 쉽게 정리하면 좋겠다\n",
    "\n",
    "# -Aggregation 함수 적용\n",
    "Aggregation 함수: min(), max(), sum(), count() 등.\n",
    "    DataFrame에 적용한다.\n",
    "    모든 칼럼에 해당 aggregation을 적용한다.\n",
    "    ex) titanic_df에 count() 적용.\n",
    "        titanic_df.count()\n",
    "        >> 각 칼럼에 대해 적용된 값 출력한다.\n",
    "    \n",
    "    특정 칼럼에 aggregation 함수를 적용하기 위해서는, \n",
    "    DataFrame에 대상 칼럼들만 추출하면 된다.\n",
    "    ex) titanic_df[['Age','Fare']].mean()\n",
    "\n",
    "\n",
    "# -groupby() 적용\n",
    "Pandas의 groupby()는 분석 작업에 매우 많이 활용된다.\n",
    "매개 by에 칼럼을 지정하면, 대상 칼럼으로 groupby 된다.\n",
    "DataFrame에 groupby() 호출하면, DataFrameGroupBy 반환.\n",
    "ex) titanic_groupby = titanic_df.groupby(by='Pclass')\n",
    "    >> Pclass 칼럼 기준으로 GroupBy된 DataFrameGroupby 객체를 반환한다.\n",
    "    \n",
    "DataFrame에 groupby()를 적용한 결과에 aggregation 함수를 호출하면,\n",
    "    groupby() 대상 칼럼을 제외한 모든 칼럼에 해당 aggregation 함수를 적용합니다.\n",
    "    ex) titanic_groupby = titanic_df.groupby('Pclass')[['PassengerId','Survived']].count()\n",
    "\n",
    "서로 다른 aggregation 함수를 적용할 경우, 여러 함수명을 DataFrameGroupBy 객체의 agg() 내에 인자로 입력한다.\n",
    "    ex) titanic_df.groupby('Pclass')['Age'].agg([max,min]) **\n",
    "\n",
    "ex) max(Age), sum(SibSp), avg(Fare)\n",
    "    agg_format = {'Age':'max', 'SibSp':'sum', 'Fare':'mean'} **\n",
    "    titanic_df.groupby('Pclass').agg(agg_format) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 결손 데이터 처리하기\n",
    "결손 데이터: 칼럼 값이 NULL인 경우.\n",
    "    넘파이의 NaN으로 표시한다.\n",
    "    NaN 여부를 확인하는 API: isna()\n",
    "    NaN 값을 대체하는 API: fillna()\n",
    "\n",
    "# -isna()로 결손 데이터 여부 확인\n",
    "DataFrame에 isna() 수행 -> 모든 칼럼의 값이 NaN인지 True/False 반환.\n",
    "ex) titanic_df.insa().head(3)\n",
    "    모든 칼럼값이 T/F.\n",
    "    3행 출력됨.\n",
    "    \n",
    "결손 데이터의 개수는 isna()에 sum()를 추가해 구한다.\n",
    "    True는 1, False는 0으로 계산된다.\n",
    "\n",
    "# -fillna()로 결손 데이터 대체하기\n",
    "ex) Cabin 칼럼의 NaN 값을 C000으로 대체한다\n",
    "    titanic_df['Cabin'] = titanic_df['Cabin'].fillna('C000')\n",
    "\n",
    "주의해야 할 점: fillna() 반환값을 원래 변수로 받거나 (예제처럼),\n",
    "    inplace=True 매채를 fillna()에 추가해야\n",
    "    실제 데이터 세트 값이 변경된다.\n",
    "    ex) titanic_df['Cabin'].fillna('C000', inplace=True)\n",
    "    나는 후자가 더 좋다!\n",
    "    \n",
    "ex) Age 칼럼의 NaN 값을 평균 나이로,\n",
    "    Embarked 칼럽의 NaN 값을 S로 대체.\n",
    "    titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "    titanic_df['Embarked'].fillna('S', inplace=True)\n",
    "    titanic_df.isna().sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 apply lambda 식으로 데이터 가공\n",
    "apply()에 lambda 식을 결합해, DataFrame이나 Series의 레코드별로 데이터를 가공한다.\n",
    "(그러니까 DataFrame, Series에 apply()를 적용한다는 말?)\n",
    "판다스의 경우, 칼럼에 일괄적으로 데이터 가공을 하는 것이 속도 면에서 유리하나,\n",
    "복잡한 데이터 가공의 경우, apply lambda를 이용한다.\n",
    "\n",
    ">> lambda 식\n",
    "ex) lambda_square = lambda x: x**2\n",
    "    print('3의 제곱은:', lambda_square(3))\n",
    "    \n",
    "lambda 식을 이용할 때, 여러 개의 값을 인자로 사용해야 할 경우, map() 함수를 결합한다.\n",
    "ex) a = [1,2,3]\n",
    "    squares = map(lambda x: x**2, a)\n",
    "    list(squares)\n",
    "    >> [1,4,9]\n",
    "    ?? map(왼,오) 오른쪽 인자를 입력으로, 왼쪽 거쳐서 출력한거? 시발\n",
    "    \n",
    ">> DataFrame의 apply()에 lambda 적용\n",
    "ex) Name 칼럼의 문자열 개수를, Name_len에 생성\n",
    "    titanic_df['Name_len'] = titanic_df['Name'].apply(lambda x: len(x))\n",
    "    \n",
    "Lambda 식에 if-else문을 이용해, 좀 더 복잡한 가공해보자.\n",
    "ex) 나이가 15세 미만이면 Child, 그렇지 않으면 Adult로 구분하는, 칼럼 Child_Adult 생성한다.\n",
    "    titanic_df['Child_Adult'] = titanic_df['Age'].apply(lambda x: 'Child' if x<=15 else 'Adult')\n",
    "    if-else만 지원하고, else if는 지원하지 않는다.\n",
    "    else if를 사용하려면, else 절의 ()에 다시 if-else를 적용한다.\n",
    "    ex) 나이가 15세 이하이면 Child, 15~60세 이면 Adult, 60세 이상은 Elderly로 분류하는 Age_Cat 칼럼 생성.\n",
    "        titanic_df['Age_Cat'] = titanic_df['Age'].apply(lambda x: 'Child' if x<15 else('Elderly' if x>=60 else 'Adult'))\n",
    "        titanic_df['Age_Cat'].value_counts()\n",
    "        >> Adult 786, child 83, Elderly 22\n",
    "        \n",
    "    else if가 많이 나와야 하는 경우나, switch case 문의 경우, else를 계속 내포하기 부담스러움.\n",
    "    이 경우에는 별도의 함수를 만드는 게 더 낫다.\n",
    "    마지막으로, 나이에 따라 더 세분화된 분류를 해보자.\n",
    "    ex) 5살 이하는 Baby, 12살 이하는 Child, 18살 이하는 Teenage, 25살 이하는 Student, \n",
    "        35살 이하는 Young Adult, 60세 이하는 Adult, 그 이상의 Elderly로 분류.\n",
    "        \n",
    "        def get_category(age): #lambda에 이용할 함수 선언 \n",
    "            cat = ''\n",
    "            if age<=5: cat='Baby'\n",
    "            elif age<=12: cat='Child'\n",
    "            elif age<=18: cat='Teenage'\n",
    "            elif age<=25: cat='Student'\n",
    "            elif age<=35: cat='Young Adult'\n",
    "            elif age<=60: cat='Adult'\n",
    "            else: cat='Elderly'\n",
    "                \n",
    "            return cat\n",
    "        \n",
    "        titanic_df['Age_Cat'].apply(lambda x: get_category(x), inplace=True) **\n",
    "        \n",
    "-끝-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상위 60%값은 Serie 객체의 quantile()을 이용해 추출합니다.\n",
    "    ex) m = movies_df['vote_count'].quantile(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.pivot_table('rating', index='userId', columns='movieId')와 같이\n",
    "    호출하면 로우 레벨은 userId, 칼럼은 모두 movieId 칼럼이 있는 값으로\n",
    "    칼럼 이름이 바뀌고, 데이터는 rating 칼럼이 있는 값이 할당됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title 칼럼을 얻기 위해 movies와 조인\n",
    "rating_movies = pd.merge(ratings, movies, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.columns 로 칼럼명에 접근할 수 있다\n",
    "ex) item_sim_df = pd.DataFrame(data=item_sim, index=ratings_matrix.columns, \n",
    "                               columns=ratings_matrix.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list comprehension으로 already_seem에 해당하는 영화는 movies_list에서 제외한다\n",
    "unseen_list = [movie for movie in movies_list if movie not in already_seen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균,분산\n",
    "print('feature 들의 평균값:\\n', iris_df.mean())\n",
    "print('\\nfeature들의 분산값:\\n', iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 데이터세트에서 Null 값 확인\n",
    "print('데이터 세트 Null 값 개수', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list의 element를 공백없이 붙인다\n",
    "''.join(list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_a = ['1', '2', '3', '4']   -> list_a = [1, 2, 3, 4] 로 바꾸고 싶을 때,\n",
    "map(int, list_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list)) #보면 알지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
